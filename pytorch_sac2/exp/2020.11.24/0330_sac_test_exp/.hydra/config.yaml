agent:
  class: agent.sac.SACAgent
  name: sac
  params:
    action_dim: ???
    action_range: ???
    actor_betas:
    - 0.9
    - 0.999
    actor_cfg: ${diag_gaussian_actor}
    actor_lr: 0.0001
    actor_update_frequency: 1
    alpha_betas:
    - 0.9
    - 0.999
    alpha_lr: 0.0001
    batch_size: 256
    critic_betas:
    - 0.9
    - 0.999
    critic_cfg: ${double_q_critic}
    critic_lr: 0.0001
    critic_target_update_frequency: 2
    critic_tau: 0.005
    device: ${device}
    discount: 0.99
    init_temperature: 0.1
    learnable_temperature: true
    obs_dim: ???
device: cpu
diag_gaussian_actor:
  class: agent.actor.DiagGaussianActor
  params:
    action_dim: ${agent.params.action_dim}
    hidden_depth: 2
    hidden_dim: 256
    log_std_bounds:
    - -5
    - 2
    obs_dim: ${agent.params.obs_dim}
double_q_critic:
  class: agent.critic.DoubleQCritic
  params:
    action_dim: ${agent.params.action_dim}
    hidden_depth: 2
    hidden_dim: 256
    obs_dim: ${agent.params.obs_dim}
env: cheetah_run
eval_frequency: 10000
experiment: test_exp
log_frequency: 10000
log_save_tb: true
num_eval_episodes: 10
num_seed_steps: 5000
num_train_steps: 1000000.0
replay_buffer_capacity: ${num_train_steps}
save_video: true
seed: 1
